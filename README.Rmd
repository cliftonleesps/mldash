---
output: github_document
---

```{r, include = FALSE}
library(dplyr)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
options(digits = 2)
```

# mldash

<!-- badges: start -->
<!-- badges: end -->

The goal of `mldash` is to provide a framework for evaluating the performance of many predictive models across many datasets. The package includes common predictive modeling procedures and datasets. Details on how to contribute additional datasets and models is outlined below. Both datasets and models are defined in the Debian Control File (dcf) format. This provides a convenient format for storing both metadata about the datasets and models but also R code snippets for retrieving data, training models, and getting predictions. The `run_models` function handles executing each model for each dataset (appropriate to the predictive model type, i.e. classification or regression), splitting data into training and validation sets, and calculating the desired performance metrics utilizing the [`yardstick`](https://yardstick.tidymodels.org) package.


## Installation

You can install the development version of `mldash` using the `remotes` package like so:

``` r
remotes::install_github('jbryer/mldash')
```

## Running Predictive Models

To begin, we read in the datasets using the `read_ml_datasets()` function. There are two parameters:

* `dir` is the directory containing the metadata files. The default is to look in the package's installation directory.
* `cache_dir` is the directory where datasets can be stored locally.

This lists the datasets currenlty included in the package (more to come soon).

```{r, eval = TRUE, message = FALSE}
ml_datasets <- mldash::read_ml_datasets(dir = 'inst/datasets',
										cache_dir = 'data-raw')
ml_datasets %>% select(name, type, model)
```

Similarly, the `read_ml_models` will read in the models. The `dir` parameter defines where to look for model files.

```{r, eval = TRUE, message = FALSE}
ml_models <- mldash::read_ml_models(dir = 'inst/models')
ml_models
```

Once the datasets and models have been loaded, the `run_models` will train and evaluate each model for each dataset as appropriate for the model type.

```{r, eval = TRUE}
ml_results <- mldash::run_models(datasets = ml_datasets, models = ml_models)
ml_results
```


## Creating Datasets

```{r, eval = FALSE}
adult_data <- mldash::new_dataset(
	name = 'adult',
	type = 'classification',
	description = 'Prediction task is to determine whether a person makes over 50K a year.',
	source = 'https://archive.ics.uci.edu/ml/datasets/Adult',
	url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',
	dir = 'inst/datasets',
	data = function() {
		destfile <- tempfile()
		download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", destfile)
		df <- read.csv(destfile, header = FALSE)
		names(df) <- c('age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',
					   'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'captial-loss',
					   'hours-per-week', 'native-country', 'greater_than_50k')
		df$greater_than_50k <- df$greater_than_50k == ' >50K'
		return(df)
	},
	model = greater_than_50k ~ .,
	overwrite = TRUE
)
```

Results in creating the following file:

```
name: adult
type: classification
description: Prediction task is to determine whether a person makes over 50K a year.
source: https://archive.ics.uci.edu/ml/datasets/Adult
reference: APA reference for the dataset.
url: https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data
data: function () 
	{
	    destfile <- tempfile()
	    download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", 
	        destfile)
	    df <- read.csv(destfile, header = FALSE)
	    names(df) <- c("age", "workclass", "fnlwgt", "education", 
	        "education-num", "marital-status", "occupation", "relationship", 
	        "race", "sex", "capital-gain", "captial-loss", "hours-per-week", 
	        "native-country", "greater_than_50k")
	    df$greater_than_50k <- df$greater_than_50k == " >50K"
	    return(df)
	}
model: greater_than_50k ~ .
note:
```

## Creating Models

```{r, eval = FALSE}
rf_model <- mldash::new_model(
	name = 'randomForest',
	type = 'classification',
	description = 'Random forest prediction model usign the randomForest R package.',
	train_fun = function(formula, data) {
		y_var <- all.vars(formula)[1]
		if(!is.factor(data[,y_var])) {
			data[,y_var] <- as.factor(data[,y_var])
		}
		randomForest::randomForest(formula = formula, data = data, ntree = 1000)
	},
	predict_fun = function(model, newdata) {
	    y_var <- all.vars(model$terms)[1]
		if(!is.factor(newdata[,y_var])) {
			newdata[,y_var] <- as.factor(newdata[,y_var])
		}
	    randomForest:::predict.randomForest(model, newdata = newdata, type = "prob")[,2,drop=TRUE]
	},
	packages = "randomForest",
	overwrite = TRUE
)
```

Results in the following file:

```
name: randomForest
type: classification
description: Random forest prediction model usign the randomForest R package.
train: function (formula, data) 
	{
		y_var <- all.vars(formula)[1]]
		if(!is.factor(data[,y_var)) {
			data[,y_var] <- as.factor(data[,y_var])
		}
	    randomForest::randomForest(formula = formula, data = data, 
	        ntree = 1000)
	}
predict: function (model, newdata) 
	{
		y_var <- all.vars(formula)[1]]
		if(!is.factor(newdata[,y_var)) {
			newdata[,y_var] <- as.factor(newdata[,y_var])
		}
	    randomForest:::predict.randomForest(model, newdata = newdata, type = "prob")[,2,drop=TRUE]
	}
note:
```




## Code of Conduct

Please note that the mldash project is released with a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.

